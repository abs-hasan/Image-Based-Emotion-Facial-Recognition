{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84aa79a7-d946-4c20-b8ef-ee6aefc76f70",
   "metadata": {},
   "source": [
    "## Project : Image Based-Emotion Facial Recognition\n",
    "##### Dataset : https://www.kaggle.com/datasets/msambare/fer2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b358c09-2e35-4c80-9bcc-53fa1f4dc6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all necessary Libraries\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNet, InceptionV3, ResNet50, VGG16\n",
    "\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a43d68-f8a3-4d46-8e15-e411f2c786b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory location for the dataset\n",
    "location = \"old/data\"\n",
    "\n",
    "# Get the list of datasets in the specified location\n",
    "name_of_dataset = os.listdir(location)\n",
    "\n",
    "# Create a list of emotions based on the contents of the 'train' directory\n",
    "emotion_list = os.listdir(location + \"/train\")\n",
    "\n",
    "# Print the list of dataset names and emotions\n",
    "print(name_of_dataset)\n",
    "print(emotion_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c21b3b2-9834-463f-9308-9aeb27ee7942",
   "metadata": {},
   "source": [
    "### Visualization of Emotion Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968b6bd7-0660-4a94-bac6-2b9d77c16ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists to store image data and labels\n",
    "images = []\n",
    "target_lbl = []\n",
    "target_idx = []\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Define the number of rows and columns for the subplots\n",
    "num_rows = 4\n",
    "num_cols = 7\n",
    "\n",
    "# Create a grid of subplots with a larger figure size\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(12, 7))\n",
    "\n",
    "# Define the list of emotions\n",
    "emotions = emotion_list\n",
    "\n",
    "# Initialize a dictionary to count the occurrences of each emotion\n",
    "emotion_counts = {}\n",
    "\n",
    "# Iterate through the emotions\n",
    "for i, emotion in enumerate(emotions):\n",
    "    # Get a list of image file paths for the current emotion\n",
    "    image_files = glob.glob(location + f'/train/{emotion}/*')\n",
    "    all_image_files = []\n",
    "    \n",
    "    # Count and store the number of images for each emotion\n",
    "    emotion_counts[emotion] = len(image_files)\n",
    "    \n",
    "    # Shuffle the image file list\n",
    "    random.shuffle(image_files)\n",
    "    \n",
    "    # Display up to 4 randomly selected images for each emotion\n",
    "    for j in range(min(4, len(image_files))):\n",
    "        file_name = image_files[j]\n",
    "        img = cv2.imread(file_name)\n",
    "        row = j\n",
    "        col = i\n",
    "        axs[row, col].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        axs[row, col].set_xticks([])\n",
    "        axs[row, col].set_yticks([])\n",
    "        axs[row, col].set_xlabel(emotion)\n",
    "\n",
    "# Add a title\n",
    "plt.suptitle(\"Visualization of Emotion Datasets\", fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30df80c1-a565-4883-95c3-6bebcfe6cd9e",
   "metadata": {},
   "source": [
    "### Training Class Distribution in the Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6137d7-65a7-4fac-ba1a-8c36046cc24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the emotion counts by values (counts)\n",
    "sorted_emotion_counts = {k: v for k, v in sorted(emotion_counts.items(), key=lambda item: item[1])}\n",
    "\n",
    "# Define a list of colors for each emotion\n",
    "colors = ['#B2C8BA', '#80B3FF', '#D988B9', '#BC7AF9', '#9ED2BE', '#7895CB', 'cyan', 'magenta']\n",
    "\n",
    "# Create a horizontal bar chart for sorted emotion counts with custom colors\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.barh(y=list(sorted_emotion_counts.keys()), width=list(sorted_emotion_counts.values()), color=colors)\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Emotion')\n",
    "plt.title('Value Counts per Emotion')\n",
    "plt.gca().invert_yaxis() \n",
    "\n",
    "# Add text labels for each bar\n",
    "for bar in bars:\n",
    "    plt.text(bar.get_width() + 180, bar.get_y() + bar.get_height() / 2, str(int(bar.get_width())), ha='center', va='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ecd9a6-2bae-441c-b027-ca9a8d35f02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_counts = {\n",
    "    'Angry': 2369,\n",
    "    'Disgust': 348,\n",
    "    'Fear': 4097,\n",
    "    'Happy': 7215,\n",
    "    'Sad': 4830,\n",
    "    'Surprise': 3170,\n",
    "    'Neutral': 4965\n",
    "}\n",
    "\n",
    "# labels and counts for the pie chart\n",
    "labels = emotion_counts.keys()\n",
    "counts = emotion_counts.values()\n",
    "\n",
    "# Custom colors\n",
    "colors = ['#B2C8BA', '#80B3FF', '#D988B9', '#BC7AF9', '#9ED2BE', '#7895CB', 'cyan', 'magenta']\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(counts, labels=labels, autopct='%1.1f%%', startangle=140, colors=colors)\n",
    "plt.title('Class Distribution')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08985ab7-e8dd-4c51-b5c7-d2a7efd317b5",
   "metadata": {},
   "source": [
    "### Image Shape Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d32e99-832b-45ba-8b98-0fa614ee6ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to train image files\n",
    "path = \"data/train/\"\n",
    "\n",
    "# Initialize an empty list to store image arrays\n",
    "image_arrays = []\n",
    "\n",
    "# Use glob to find all image files in subdirectories\n",
    "image_files = glob.glob(os.path.join(path, '**/*.jpeg'), recursive=True)\n",
    "\n",
    "# Read and store each image in the list\n",
    "for image_file in image_files:\n",
    "    img = cv2.imread(image_file)\n",
    "    image_arrays.append(img)\n",
    "\n",
    "    # Normalize the pixel values to a range between 0 and 1\n",
    "    normalized_img = img / 255.0\n",
    "\n",
    "# Initialize a flag to check if all images have the same shape\n",
    "same_shape = True\n",
    "\n",
    "# Iterate through the image arrays\n",
    "for i in range(1, len(image_arrays)):\n",
    "    if np.shape(image_arrays[i]) != np.shape(image_arrays[0]):\n",
    "        same_shape = False\n",
    "        break\n",
    "\n",
    "# Check if all images have the same shape\n",
    "if same_shape:\n",
    "    print(\"All images have the same shape.\")\n",
    "else:\n",
    "    print(\"Not all images have the same shape.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f8ba37-c102-497b-a444-ea531d5fe509",
   "metadata": {},
   "source": [
    "### Emotion Dataset Information and Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219d2ed1-f783-47ff-a5ab-d93996c79e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store dataset information\n",
    "dataset_info = []\n",
    "\n",
    "for emotion, count in emotion_counts.items():\n",
    "    dataset_info.append({'Emotion': emotion, 'Count': count})\n",
    "\n",
    "# Create a DataFrame from the dataset information\n",
    "dataset_df = pd.DataFrame(dataset_info)\n",
    "\n",
    "# Descriptive statistics for your dataset\n",
    "statistics = dataset_df.describe()\n",
    "print(statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4731ee28-85f3-41a9-b72b-8e0ee6c189ee",
   "metadata": {},
   "source": [
    "The dataset contains information about seven different emotions. On average, each emotion is represented by approximately 3,856 images, with some having as few as 348 and others as many as 7,215 images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a052f2f-ddbd-4550-82cb-e6a8fcb215a0",
   "metadata": {},
   "source": [
    "### Data Preprocessing and Augmentation for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829a9b08-3865-4525-83d2-af237afbfdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to your training and testing data directories\n",
    "train_dir = 'data/train/'\n",
    "test_dir = 'data/test/'\n",
    "\n",
    "# Create an image data generator for training data with various data augmentation\n",
    "training_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize pixel values to a range of 0 to 1\n",
    "    validation_split=0.2,  # Split data for validation (20%)\n",
    "    width_shift_range=0.2,  \n",
    "    height_shift_range=0.2, \n",
    "    rotation_range=5,  # Randomly rotate images by up to 5 degrees\n",
    "    shear_range=0.2,  \n",
    "    horizontal_flip=True,  \n",
    "    vertical_flip=True,  \n",
    "    fill_mode='nearest'  # Fill missing pixels with the nearest value\n",
    ")\n",
    "\n",
    "# Create an image data generator for validation data and testing data\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.25)\n",
    "testing_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Define the image size and batch size\n",
    "image_size = 48\n",
    "batch_size = 128\n",
    "\n",
    "# Create training, validation, and testing datasets using the data generators\n",
    "training_dataset = training_datagen.flow_from_directory(\n",
    "    directory=train_dir,\n",
    "    target_size=(image_size, image_size),\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',  \n",
    "    subset='training',\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "validation_dataset = validation_datagen.flow_from_directory(\n",
    "    directory=train_dir,\n",
    "    target_size=(image_size, image_size),\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale', \n",
    "    subset='validation',\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "testing_dataset = testing_datagen.flow_from_directory(\n",
    "    directory=test_dir,\n",
    "    target_size=(image_size, image_size),\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',  \n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32516274-e7c1-424f-a097-2c2389c49425",
   "metadata": {},
   "source": [
    "### Model 1: Custom CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47020b98-a8d7-42a2-b4b3-0822497809cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Number of classes and epochs\n",
    "num_classes = 7 \n",
    "epochs = 50\n",
    "\n",
    "# Initialize the CNN model\n",
    "model = Sequential()\n",
    "\n",
    "# 1st Convolutional Layer\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(48, 48, 1), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.20))\n",
    "\n",
    "# 2nd Convolutional Layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.20))\n",
    "\n",
    "# 3rd Convolutional Layer\n",
    "model.add(Conv2D(128, (5, 5), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.20))\n",
    "\n",
    "# 4th Convolutional Layer with L2 regularization\n",
    "model.add(Conv2D(512, (5, 5), activation='relu', padding='same', kernel_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.20))\n",
    "\n",
    "# 5th Convolutional Layer with L2 regularization\n",
    "model.add(Conv2D(512, (5, 5), activation='relu', padding='same', kernel_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.20))\n",
    "\n",
    "\n",
    "# Flatten the feature maps\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully Connected Layer 1\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Fully Connected Layer 2\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Fully Connected Layer 3 (Output Layer)\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  \n",
    "    patience=10,  \n",
    "    restore_best_weights=True \n",
    ")\n",
    "\n",
    "\n",
    "# learning rate schedule\n",
    "def lr_schedule(epoch):\n",
    "    if epoch < 20:\n",
    "        return 0.01\n",
    "    elif epoch < 35:\n",
    "        return 0.001\n",
    "    else:\n",
    "        return 0.0001\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "\n",
    "# Compile the custom_CNN_model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',  \n",
    "    optimizer=Adam(learning_rate=0.001),  \n",
    "    metrics=['accuracy'] \n",
    ")\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc70606d-e576-45bb-97cd-c477958abe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    x=training_dataset, \n",
    "    epochs=epochs,  \n",
    "    validation_data=validation_dataset, \n",
    "    callbacks=[early_stopping, lr_scheduler] \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea34f6d3-7828-48f0-999a-88560ec49c87",
   "metadata": {},
   "source": [
    "### Model 1: Evaluation and Training History for the Custom CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bc5690-edbc-441e-8456-2e00d4ac48fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the testing dataset\n",
    "test_loss, test_accuracy = model.evaluate(testing_dataset)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Get the training and validation loss and accuracy from the training history\n",
    "training_loss = history.history['loss']\n",
    "validation_loss = history.history['val_loss']\n",
    "training_accuracy = history.history['accuracy']\n",
    "validation_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Plot the training and validation loss and accuracy\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(training_loss, label='Training Loss')\n",
    "plt.plot(validation_loss, label='Validation Loss')\n",
    "plt.legend() \n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(training_accuracy, label='Training Accuracy')\n",
    "plt.plot(validation_accuracy, label='Validation Accuracy')\n",
    "plt.legend() \n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c46a034-aed8-4478-9516-1361cae3dad1",
   "metadata": {},
   "source": [
    "### Model 1: Evaluation and Confusion Matrix for Custom CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157eaa17-9cb8-43de-94d7-fe23fad84339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing dataset\n",
    "test_pred = model.predict(testing_dataset)\n",
    "test_pred_classes = np.argmax(test_pred, axis=1)\n",
    "true_classes = testing_dataset.classes\n",
    "\n",
    "# Generate and print the classification report\n",
    "class_labels = list(testing_dataset.class_indices.keys())\n",
    "report = classification_report(true_classes, test_pred_classes, target_names=class_labels, zero_division=1)\n",
    "print(report)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(true_classes, test_pred_classes)\n",
    "\n",
    "# Plot the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_mtx, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Custom CNN Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Make predictions on the testing dataset\n",
    "predictions = model.predict(testing_dataset)\n",
    "\n",
    "# Convert one-hot encoded labels to class labels\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Get true class labels from the testing dataset\n",
    "true_classes = testing_dataset.classes\n",
    "\n",
    "# Calculate precision, recall, and F1 score for the entire model\n",
    "precision = precision_score(true_classes, predicted_classes, average='weighted')\n",
    "recall = recall_score(true_classes, predicted_classes, average='weighted')\n",
    "f1 = f1_score(true_classes, predicted_classes, average='weighted')\n",
    "\n",
    "# Print the precision, recall, and F1 score\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f1fd2c-546c-4114-8e3b-eba6cf5425a6",
   "metadata": {},
   "source": [
    "### Model 2: MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b15675-9e71-4f7a-a28e-4024c7fdea5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Image Data Generators Configuration for MobileNet Model \n",
    "image_size = 75\n",
    "batch_size = 128\n",
    "\n",
    "training_dataset = training_datagen.flow_from_directory(\n",
    "    directory=train_dir,\n",
    "    target_size=(image_size, image_size),\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "validation_dataset = validation_datagen.flow_from_directory(\n",
    "    directory=train_dir,\n",
    "    target_size=(image_size, image_size),\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "testing_dataset = testing_datagen.flow_from_directory(\n",
    "    directory=test_dir,\n",
    "    target_size=(image_size, image_size),\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Number of classes for your classification task\n",
    "num_classes = 7 \n",
    "\n",
    "# Load the pre-trained MobileNet model\n",
    "base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
    "\n",
    "# Freeze the layers of the pre-trained model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create a custom top model with additional dense layers and dropout\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Combine the base model and the custom top model\n",
    "mobile_net_model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Compile the model\n",
    "mobile_net_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print a summary of the model architecture\n",
    "mobile_net_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d396ca-30c5-4b30-9a5f-353eeb3f9e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of training steps and validation steps\n",
    "train_steps = training_dataset.samples // batch_size\n",
    "val_steps = validation_dataset.samples // batch_size\n",
    "\n",
    "# Train the model \n",
    "history = mobile_net_model.fit(\n",
    "    training_dataset,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_data=validation_dataset,\n",
    "    validation_steps=val_steps,\n",
    "    epochs=epochs,  \n",
    "    callbacks=[early_stopping]  # Include early stopping callback\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c90869-ab56-4ea0-9662-00a859f24de3",
   "metadata": {},
   "source": [
    "### Model 2: Evaluation and Training History for MobileNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e905e932-0cf2-4c41-b212-7f6c10595b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the testing dataset\n",
    "test_loss, test_accuracy = mobile_net_model.evaluate(testing_dataset)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Get the training and validation loss and accuracy from the training history\n",
    "training_loss = history.history['loss']\n",
    "validation_loss = history.history['val_loss']\n",
    "training_accuracy = history.history['accuracy']\n",
    "validation_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Plot the training and validation loss and accuracy\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(training_loss, label='Training Loss')\n",
    "plt.plot(validation_loss, label='Validation Loss')\n",
    "plt.legend() \n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(training_accuracy, label='Training Accuracy')\n",
    "plt.plot(validation_accuracy, label='Validation Accuracy')\n",
    "plt.legend() \n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9ac84f-2b8e-4c4f-9be1-421ea326ee43",
   "metadata": {},
   "source": [
    "### Model 2: Evaluation and Confusion Matrix for MobileNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac415e1-1655-4ff6-b80d-7f4203ff0c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing dataset\n",
    "test_pred = mobile_net_model.predict(testing_dataset)\n",
    "test_pred_classes = np.argmax(test_pred, axis=1)\n",
    "true_classes = testing_dataset.classes\n",
    "\n",
    "# Generate and print the classification report\n",
    "class_labels = list(testing_dataset.class_indices.keys())\n",
    "report = classification_report(true_classes, test_pred_classes, target_names=class_labels, zero_division=1)\n",
    "print(report)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(true_classes, test_pred_classes)\n",
    "\n",
    "# Plot the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_mtx, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Make predictions on the testing dataset\n",
    "predictions = mobile_net_model.predict(testing_dataset)\n",
    "\n",
    "# Convert one-hot encoded labels to class labels\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Get true class labels from the testing dataset\n",
    "true_classes = testing_dataset.classes\n",
    "\n",
    "# Calculate precision, recall, and F1 score for the entire model\n",
    "precision = precision_score(true_classes, predicted_classes, average='weighted')\n",
    "recall = recall_score(true_classes, predicted_classes, average='weighted')\n",
    "f1 = f1_score(true_classes, predicted_classes, average='weighted')\n",
    "\n",
    "# Print the precision, recall, and F1 score\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336a6a87-9a89-47c9-997f-9e25cd9808ca",
   "metadata": {},
   "source": [
    "### Model 3: Inception3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed473d81-f628-4f39-b202-f127a7611ab6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the pre-trained InceptionV3 model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
    "\n",
    "# Freeze the layers of the pre-trained model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create a custom top model with additional dense layers and dropout\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Combine the base model and the custom top model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print a summary of the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1eee48-29cd-444b-9a67-097acee69f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of training steps and validation steps\n",
    "train_steps = training_dataset.samples // batch_size\n",
    "val_steps = validation_dataset.samples // batch_size\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    training_dataset,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_data=validation_dataset,\n",
    "    validation_steps=val_steps,\n",
    "    epochs=epochs, \n",
    "    callbacks=[early_stopping]  # Include early stopping callback\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c614b08-c8e7-43d8-8f3c-241d3146563b",
   "metadata": {},
   "source": [
    "### Model 3: Evaluation and Training History for Inception3 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55a5299-cf81-4409-860c-0c82ca60c4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the testing dataset\n",
    "test_loss, test_accuracy = model.evaluate(testing_dataset)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Get the training and validation loss and accuracy from the training history\n",
    "training_loss = history.history['loss']\n",
    "validation_loss = history.history['val_loss']\n",
    "training_accuracy = history.history['accuracy']\n",
    "validation_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Plot the training and validation loss and accuracy\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(training_loss, label='Training Loss')\n",
    "plt.plot(validation_loss, label='Validation Loss')\n",
    "plt.legend() \n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(training_accuracy, label='Training Accuracy')\n",
    "plt.plot(validation_accuracy, label='Validation Accuracy')\n",
    "plt.legend() \n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a67fad8-a511-4ce1-9c09-3ea5ac83e570",
   "metadata": {},
   "source": [
    "### Model 3: Evaluation and Confusion Matrix for Inception3 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f9e679-5ee2-45d7-a72f-8ec6816a0c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing dataset\n",
    "test_pred = model.predict(testing_dataset)\n",
    "test_pred_classes = np.argmax(test_pred, axis=1)\n",
    "true_classes = testing_dataset.classes\n",
    "\n",
    "# Generate and print the classification report\n",
    "class_labels = list(testing_dataset.class_indices.keys())\n",
    "report = classification_report(true_classes, test_pred_classes, target_names=class_labels, zero_division=1)\n",
    "print(report)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(true_classes, test_pred_classes)\n",
    "\n",
    "# Plot the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_mtx, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Make predictions on the testing dataset\n",
    "predictions = model.predict(testing_dataset)\n",
    "\n",
    "# Convert one-hot encoded labels to class labels\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Get true class labels from the testing dataset\n",
    "true_classes = testing_dataset.classes\n",
    "\n",
    "# Calculate precision, recall, and F1 score for the entire model\n",
    "precision = precision_score(true_classes, predicted_classes, average='weighted')\n",
    "recall = recall_score(true_classes, predicted_classes, average='weighted')\n",
    "f1 = f1_score(true_classes, predicted_classes, average='weighted')\n",
    "\n",
    "# Print the precision, recall, and F1 score\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1489bdc-fed1-41cc-bc1e-14f65103f05f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d8da650-0995-4d91-b6a1-0c3cc5f2b4ad",
   "metadata": {},
   "source": [
    "### Model 4: ResNet-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd311893-42a8-4b7f-96b9-6a27d379a8bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_size = 48\n",
    "batch_size = 128\n",
    "training_dataset  = training_datagen.flow_from_directory(directory = train_dir,\n",
    "                                                   target_size = (image_size, image_size),\n",
    "                                                   class_mode = 'categorical',\n",
    "                                                   #color_mode = \"grayscale\",\n",
    "                                                   subset = 'training',\n",
    "                                                   batch_size = batch_size)\n",
    "\n",
    "validation_dataset = validation_datagen.flow_from_directory(directory = train_dir,\n",
    "                                                  target_size = (image_size, image_size),\n",
    "                                                  class_mode = 'categorical',\n",
    "                                                  #color_mode = \"grayscale\",\n",
    "                                                  subset = 'validation',\n",
    "                                                  batch_size = batch_size)\n",
    "\n",
    "testing_dataset = testing_datagen.flow_from_directory(directory = test_dir,\n",
    "                                                target_size = (image_size, image_size),\n",
    "                                                class_mode = 'categorical',\n",
    "                                               # color_mode = \"grayscale\",\n",
    "                                                batch_size = batch_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num_classes = 7  \n",
    "\n",
    "# Load the pre-trained ResNet-50 model \n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
    "\n",
    "# Freeze the layers of the pre-trained model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create a custom top model with additional dense layers and dropout\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)  \n",
    "x = Dense(512, activation='relu')(x)  \n",
    "x = Dropout(0.5)(x)  \n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Combine the base model and the custom top model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print a summary of the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90c0746-4b41-47e8-892a-b77a10b06d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of training steps and validation steps\n",
    "train_steps = training_dataset.samples // batch_size\n",
    "val_steps = validation_dataset.samples // batch_size\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    training_dataset,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_data=validation_dataset,\n",
    "    validation_steps=val_steps,\n",
    "    epochs=epochs, \n",
    "    callbacks=[early_stopping]  \n",
    ")\n",
    "\n",
    "# Evaluate the model on the testing dataset\n",
    "test_loss, test_accuracy = model.evaluate(testing_dataset)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e1aac8-9c4c-41d7-b7ae-b68c0941ba31",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model 4: Evaluation and Training History for ResNet-50 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a0b143-1105-4c97-99c1-babe1230f504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the testing dataset\n",
    "test_loss, test_accuracy = model.evaluate(testing_dataset)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Get the training and validation loss and accuracy from the training history\n",
    "training_loss = history.history['loss']\n",
    "validation_loss = history.history['val_loss']\n",
    "training_accuracy = history.history['accuracy']\n",
    "validation_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Plot the training and validation loss and accuracy\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(training_loss, label='Training Loss')\n",
    "plt.plot(validation_loss, label='Validation Loss')\n",
    "plt.legend() \n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(training_accuracy, label='Training Accuracy')\n",
    "plt.plot(validation_accuracy, label='Validation Accuracy')\n",
    "plt.legend() \n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff825f4-b703-4dc0-be00-720e4ebdd6ab",
   "metadata": {},
   "source": [
    "### Model 4: Evaluation and Confusion Matrix for ResNet-50 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89850b57-3589-4097-8e95-e29ba3643842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing dataset\n",
    "test_pred = model.predict(testing_dataset)\n",
    "test_pred_classes = np.argmax(test_pred, axis=1)\n",
    "true_classes = testing_dataset.classes\n",
    "\n",
    "# Generate and print the classification report\n",
    "class_labels = list(testing_dataset.class_indices.keys())\n",
    "report = classification_report(true_classes, test_pred_classes, target_names=class_labels, zero_division=1)\n",
    "print(report)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(true_classes, test_pred_classes)\n",
    "\n",
    "# Plot the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_mtx, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Make predictions on the testing dataset\n",
    "predictions = model.predict(testing_dataset)\n",
    "\n",
    "# Convert one-hot encoded labels to class labels\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Get true class labels from the testing dataset\n",
    "true_classes = testing_dataset.classes\n",
    "\n",
    "# Calculate precision, recall, and F1 score for the entire model\n",
    "precision = precision_score(true_classes, predicted_classes, average='weighted')\n",
    "recall = recall_score(true_classes, predicted_classes, average='weighted')\n",
    "f1 = f1_score(true_classes, predicted_classes, average='weighted')\n",
    "\n",
    "# Print the precision, recall, and F1 score\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69271cc0-24d9-477f-b08c-88e040f5998f",
   "metadata": {},
   "source": [
    "### Model 5: VGG-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3a2f3b-c709-4e08-b344-6e4330a693b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7 \n",
    "\n",
    "# Load the pre-trained VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
    "\n",
    "# Freeze the layers of the pre-trained model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create a custom top model with additional dense layers and dropout\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Combine the base model and the custom top model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print a summary of the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dd8cc9-0146-4991-943d-88b01aaa63a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of training steps and validation steps\n",
    "train_steps = training_dataset.samples // batch_size\n",
    "val_steps = validation_dataset.samples // batch_size\n",
    "\n",
    "# Train the model \n",
    "history = model.fit(\n",
    "    training_dataset,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_data=validation_dataset,\n",
    "    validation_steps=val_steps,\n",
    "    epochs=epochs,  \n",
    "    callbacks=[early_stopping] \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d52be2-39b7-47c8-a99f-9437b7625072",
   "metadata": {},
   "source": [
    "### Model 5: Evaluation and Training History for VGG-16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984bc46b-8d86-4139-bbe4-b582b594a2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the testing dataset\n",
    "test_loss, test_accuracy = model.evaluate(testing_dataset)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Get the training and validation loss and accuracy from the training history\n",
    "training_loss = history.history['loss']\n",
    "validation_loss = history.history['val_loss']\n",
    "training_accuracy = history.history['accuracy']\n",
    "validation_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Plot the training and validation loss and accuracy\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(training_loss, label='Training Loss')\n",
    "plt.plot(validation_loss, label='Validation Loss')\n",
    "plt.legend()  \n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(training_accuracy, label='Training Accuracy')\n",
    "plt.plot(validation_accuracy, label='Validation Accuracy')\n",
    "plt.legend()  \n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405f66ed-21ed-46d4-b4f3-3b5589eccc84",
   "metadata": {},
   "source": [
    "### Model 5: Evaluation and Confusion Matrix for VGG-16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc31c0a-e6d5-4e05-bc14-c5108a01049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing dataset\n",
    "test_pred = model.predict(testing_dataset)\n",
    "test_pred_classes = np.argmax(test_pred, axis=1)\n",
    "true_classes = testing_dataset.classes\n",
    "\n",
    "# Generate and print the classification report\n",
    "class_labels = list(testing_dataset.class_indices.keys())\n",
    "report = classification_report(true_classes, test_pred_classes, target_names=class_labels, zero_division=1)\n",
    "print(report)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(true_classes, test_pred_classes)\n",
    "\n",
    "# Plot the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_mtx, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Make predictions on the testing dataset\n",
    "predictions = model.predict(testing_dataset)\n",
    "\n",
    "# Convert one-hot encoded labels to class labels\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Get true class labels from the testing dataset\n",
    "true_classes = testing_dataset.classes\n",
    "\n",
    "# Calculate precision, recall, and F1 score for the entire model\n",
    "precision = precision_score(true_classes, predicted_classes, average='weighted')\n",
    "recall = recall_score(true_classes, predicted_classes, average='weighted')\n",
    "f1 = f1_score(true_classes, predicted_classes, average='weighted')\n",
    "\n",
    "# Print the precision, recall, and F1 score\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2cb79e-41bc-46d8-9572-39f6dac294a1",
   "metadata": {},
   "source": [
    "### Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a3d66f-0d4b-4020-a694-fdf89791e1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Model names and corresponding test accuracy values\n",
    "model_names = [\"Custom CNN Model\", \"ResNet50\", \"MobileNet\", \"VGG16\", \"Inception3\"]\n",
    "test_accuracy = [29.17, 24.71, 42.98, 38.62, 34.01]\n",
    "\n",
    "# Original colors for each model\n",
    "original_colors = ['lightblue', 'lightgreen', 'lightcoral', 'lightsalmon', 'lightpink']\n",
    "\n",
    "# Sort the models by test accuracy in descending order\n",
    "sorted_data = sorted(zip(model_names, test_accuracy, original_colors), key=lambda x: x[1], reverse=True)\n",
    "model_names_sorted, test_accuracy_sorted, original_colors_sorted = zip(*sorted_data)\n",
    "\n",
    "# Create a bar chart with original colors\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(model_names_sorted, test_accuracy_sorted, color=original_colors_sorted)\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Test Accuracy (%)')\n",
    "plt.title('Test Accuracy of Different Models')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Display the test accuracy values on top of the bars\n",
    "for i, acc in enumerate(test_accuracy_sorted):\n",
    "    plt.text(model_names_sorted[i], acc + 1, f'{acc:.2f}%', ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdec7ca-b65b-4727-89a2-687518188ab9",
   "metadata": {},
   "source": [
    "### Save the trained model to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea4310c-f1b8-4f9a-8939-0f516425168b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile_net_model.save('my_best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b9c37c-90cf-42f1-982e-808474398b23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d381dd-69ed-424d-8bb2-47e1f17dddd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01324c3e-d52e-4786-8e60-0fd3339c6238",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
